[Learn to Unlearn: Insights into Machine Unlearing](https://arxiv.org/abs/2305.07512): 

> Sekhari et al. tackled this matter by undertaking an exhaustive exploration of generalization in machine unlearning, with the objective of achieving commendable performance on new data points.
> 
>  In contrast to earlier research, the algorithms deployed in this study do not require the unlearning algorithm to have access to the training data during the deletion of samples. This study delineates a clear distinction between differential privacy and machine unlearning; 
> 
> however, it does contain a few limitations. Specifically, it does not provide dimensiondependent information-theoretic lower bounds on the deletion capacity and is unable to handle non-convex loss functions.